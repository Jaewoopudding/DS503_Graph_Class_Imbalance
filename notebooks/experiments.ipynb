{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.datasets import CoraFull, Planetoid, CitationFull\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "from models import GAT, GraphSAGE, GIN\n",
    "from utils import train_model, test_model, train_constrative_model, valid_model\n",
    "from mean_average_distance import MAD, MADGap\n",
    "from virtualnode import VirtualClassNode, UnidirectionalVirtualClassNode\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'results'\n",
    "EARLY_STOPPING = 30\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "dataset = CitationFull(root='dataset/Cora', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "df = pd.DataFrame(data.x)\n",
    "df['y'] = data.y\n",
    "train, valid = train_test_split(df, stratify=df.y, test_size=0.4)\n",
    "valid, test = train_test_split(valid, stratify=valid.y, test_size=0.5)\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train.index]=True\n",
    "data.valid_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.valid_mask[valid.index]=True\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test.index]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = MAD(device=device, global_flag=True)\n",
    "madgap = MADGap(device, 3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UnidirectionalVirtualClassNode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125486/348541044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m hyperparameters = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'virtualnode'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mUnidirectionalVirtualClassNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVirtualClassNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'temperature'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'constrative_coef'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UnidirectionalVirtualClassNode' is not defined"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'virtualnode' : [UnidirectionalVirtualClassNode(), VirtualClassNode()],\n",
    "    'temperature' : np.linspace(0.1, 1, num=10),\n",
    "    'constrative_coef' : np.logspace(-4, -1, 6),\n",
    "    'lr': np.logspace(-4, -2, 5)\n",
    "}\n",
    "\n",
    "tuning_result = pd.DataFrame({\n",
    "                            'model' : [],\n",
    "                            'virtualnode' : [],\n",
    "                            'temperature' : [],\n",
    "                            'constrative coef' : [],\n",
    "                            'lr' : [],\n",
    "                            'train_acc' : [],\n",
    "                            'train_loss' : [],\n",
    "                            'val_acc' : [],\n",
    "                            'val_loss' : [],\n",
    "                            'test_acc' : [],\n",
    "                            'macro f1' : [],\n",
    "                            'micro f1'\n",
    "                            'minor f1' : [],\n",
    "                            'mad' : [],\n",
    "                            'madgap' : []                            \n",
    "                            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125486/3977563818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvirtualnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'virtualnode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvirtualnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata_for_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mconstrative_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "for virtualnode in hyperparameters['virtualnode']:\n",
    "    if virtualnode is None:\n",
    "        vc = 'None'\n",
    "        data_for_tuning = data\n",
    "        constrative_flag = False\n",
    "    else:\n",
    "        vc = virtualnode\n",
    "        data_for_tuning = vc.forward(data)\n",
    "        constrative_flag = True\n",
    "        \n",
    "    for temperature in hyperparameters['temperature']:\n",
    "        for constrative_coef in hyperparameters['constrative_coef']:\n",
    "            for lr in hyperparameters['lr']:\n",
    "                models = [GraphSAGE(in_channels=dataset.num_features, hidden_channels=256, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device)]\n",
    "                for model in models:\n",
    "                    print(f'VC : {vc}, temp : {temperature:.5f}, constrative coef : {constrative_coef:.5f}, lr : {lr:.5f} ')\n",
    "                    max_loss = 10000\n",
    "                    early_stopping_count = 0\n",
    "                    print(f'Model: {model.name} | Number of parameters: {model.get_n_params()}')\n",
    "                    model = model.to(device)\n",
    "                    data_for_tuning = data_for_tuning.to(device)\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    losses = []\n",
    "                    accs = []\n",
    "                    val_losses = []\n",
    "                    val_accs = []\n",
    "                    for epoch in range(5000):\n",
    "                        loss, acc = train_constrative_model(model, data_for_tuning, optimizer, criterion, cnode_weight=2,\n",
    "                                                            constrative_coef=constrative_coef, temperature=temperature, positive_sampling=True)\n",
    "                        losses.append(loss.item())\n",
    "                        accs.append(100*acc)\n",
    "                        val_loss, val_acc = valid_model(model, data_for_tuning, criterion, cnode_weight=2,\n",
    "                                                        constrative_coef=constrative_coef, temperature=temperature, positive_sampling=True)\n",
    "                        val_accs.append(100*val_acc)\n",
    "                        if val_loss < max_loss:\n",
    "                            max_loss = val_loss\n",
    "                            early_stopping_count = 0\n",
    "                        else:\n",
    "                            early_stopping_count += 1\n",
    "                            if early_stopping_count > EARLY_STOPPING:\n",
    "                                print(\"Early stopping..\")\n",
    "                                break\n",
    "                        if epoch%10==0:\n",
    "                            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train Acc: {100*acc:.2f}, Valid Loss: {val_loss:.4f}, Valid Acc: {100*val_acc:.2f}')\n",
    "                        if epoch > 500:\n",
    "                            if val_acc < 0.1:\n",
    "                                print('underfitting...')\n",
    "                                break\n",
    "                    report = test_model(model, data_for_tuning)\n",
    "                    result = pd.DataFrame(report).T\n",
    "                    result_sliced = result.iloc[:-3 if len(result) < 23 else 20, :]\n",
    "                    test_acc = result.loc['accuracy'][0]\n",
    "                    result.loc['minorities-f1',:] = result_sliced.mean(axis=0)\n",
    "                    result.to_csv(os.path.join(SAVE_PATH, f'{model.name}_layers{model.num_of_hidden_layers}_neurons{model.hidden_channels}'+'.csv'))\n",
    "                    result = model(data_for_tuning.x.to(device), data_for_tuning.edge_index.to(device))[1].cpu()\n",
    "                    global_mad = mad(result).item()\n",
    "                    mad_gap = madgap(result, data_for_tuning.edge_index).item()\n",
    "                    \n",
    "                    exp_result_dict = {\n",
    "                        'model' : model.name,\n",
    "                        'virtualnode' : vc,\n",
    "                        'temperature' : temperature,\n",
    "                        'constrative coef' : constrative_coef,\n",
    "                        'lr' : lr,\n",
    "                        'train_acc' : acc,\n",
    "                        'train_loss' : loss,\n",
    "                        'val_acc' : val_acc,\n",
    "                        'val_loss' : val_loss,\n",
    "                        'test_acc' : test_acc,\n",
    "                        'macro f1' : pd.DataFrame(report).T.loc['macro avg', 'f1-score'],\n",
    "                        'micro f1' : pd.DataFrame(report).T.loc['weighted avg', 'f1-score'],\n",
    "                        'minor f1' : pd.DataFrame(report).T[:-3].sort_values(by='support', ascending=False)[-11:].mean()['f1-score'],\n",
    "                        'mad' : global_mad,\n",
    "                        'madgap' : mad_gap                            \n",
    "                    }\n",
    "                    \n",
    "                    tuning_result = tuning_result.append(exp_result_dict, ignore_index=True)\n",
    "                    \n",
    "                    print(f'global_mad: {global_mad}')\n",
    "                    print(f'madgap: {mad_gap}')\n",
    "                    print(f'Test Acc: {100*test_acc}')\n",
    "                    \n",
    "                    print('==========================================', end='\\n\\n')\n",
    "                    del model\n",
    "                    torch.cuda.empty_cache()   \n",
    "                    \n",
    "    del data_for_tuning     \n",
    "    torch.cuda.empty_cache()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_result.to_csv('tuning result', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
