{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import CoraFull, Planetoid, CitationFull\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import torch_geometric.nn as gnn \n",
    "\n",
    "from models import GAT, GraphSAGE, GIN\n",
    "from utils import train_model, test_model, train_constrative_model, valid_model\n",
    "from mean_average_distance import MAD, MADGap\n",
    "from virtualnode import VirtualClassNode, UnidirectionalVirtualClassNode\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SAVE_PATH = 'results'\n",
    "LR = 0.01\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CitationFull(root='dataset/Cora', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "df = pd.DataFrame(data.x)\n",
    "df['y'] = data.y\n",
    "train, valid = train_test_split(df, stratify=df.y, test_size=0.4)\n",
    "valid, test = train_test_split(valid, stratify=valid.y, test_size=0.5)\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train.index]=True\n",
    "data.valid_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.valid_mask[valid.index]=True\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test.index]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = UnidirectionalVirtualClassNode()\n",
    "data = vc.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: GraphSAGE, params: 4853760\n"
     ]
    }
   ],
   "source": [
    "sage = GraphSAGE(in_channels=dataset.num_features, hidden_channels=256, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device)\n",
    "\n",
    "models = [sage]\n",
    "\n",
    "for model in models:\n",
    "    print(f'model: {model.name}, params: {model.num_of_parameters}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GraphSAGE | Number of parameters: 4853760\n",
      "Epoch: 000, Train Loss: 11.8682, Train Acc: 1.00, Valid Loss: 15.5936, Valid Acc: 0.65\n",
      "Epoch: 001, Train Loss: 14.5387, Train Acc: 0.68, Valid Loss: 14.4934, Valid Acc: 3.92\n",
      "Epoch: 002, Train Loss: 14.2706, Train Acc: 3.95, Valid Loss: 17.0385, Valid Acc: 1.51\n",
      "Epoch: 003, Train Loss: 16.9500, Train Acc: 1.85, Valid Loss: 14.9933, Valid Acc: 0.27\n",
      "Epoch: 004, Train Loss: 14.6918, Train Acc: 1.05, Valid Loss: 18.1947, Valid Acc: 2.51\n",
      "Epoch: 005, Train Loss: 18.1517, Train Acc: 2.27, Valid Loss: 19.0201, Valid Acc: 4.27\n",
      "Epoch: 006, Train Loss: 18.9994, Train Acc: 2.62, Valid Loss: 17.5794, Valid Acc: 1.29\n",
      "Epoch: 007, Train Loss: 17.3754, Train Acc: 2.19, Valid Loss: 14.8087, Valid Acc: 0.40\n",
      "Epoch: 008, Train Loss: 13.5586, Train Acc: 0.82, Valid Loss: 14.9475, Valid Acc: 1.51\n",
      "Epoch: 009, Train Loss: 13.5566, Train Acc: 2.03, Valid Loss: 15.4316, Valid Acc: 3.25\n",
      "Test Acc: 3.2710280373831773\n",
      "==========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaewoo/anaconda3/envs/torch_tutorial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jaewoo/anaconda3/envs/torch_tutorial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jaewoo/anaconda3/envs/torch_tutorial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_losses = []\n",
    "model_accs = []\n",
    "for model in models:\n",
    "    print(f'Model: {model.name} | Number of parameters: {model.get_n_params()}')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "    losses = []\n",
    "    accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    for epoch in range(10):\n",
    "        loss, acc = train_constrative_model(model, data, optimizer, criterion, constrative_coef=0.03, temperature=0.2)\n",
    "        losses.append(loss.item())\n",
    "        accs.append(100*acc)\n",
    "        \n",
    "        val_loss, val_acc = valid_model(model, data, criterion, constrative_flag=True, constrative_coef=0.03, temperature=0.2)\n",
    "        val_accs.append(100*val_acc)\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train Acc: {100*acc:.2f}, Valid Loss: {val_loss:.4f}, Valid Acc: {100*val_acc:.2f}')\n",
    "    model_losses.append(losses)\n",
    "    model_accs.append(accs)\n",
    "    report = test_model(model, data)\n",
    "    result = pd.DataFrame(report).T\n",
    "    result_sliced = result.iloc[:-3 if len(result) < 23 else 20, :]\n",
    "    acc = result.loc['accuracy'][0]\n",
    "    result.loc['minorities-f1',:] = result_sliced.mean(axis=0)\n",
    "    result.to_csv(os.path.join(SAVE_PATH, f'{model.name}_layers{model.num_of_hidden_layers}_neurons{model.hidden_channels}'+'.csv'))\n",
    "    print(f'Test Acc: {100*acc}')\n",
    "    print('==========================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19863, 8710], edge_index=[2, 150592], y=[19863], train_mask=[19863], valid_mask=[19793], test_mask=[19793], edge_type=[150592])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(20).unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# MAD and MADGap Usage Example\n",
    "mad = MAD(device=device, global_flag=True)\n",
    "result = model(dataset.data.x.to(device), dataset.data.edge_index.to(device))[0].cpu()\n",
    "print(mad(result))\n",
    "madgap = MADGap(device, 3, 8)\n",
    "print(madgap(result, dataset.data.edge_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
