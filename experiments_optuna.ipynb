{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.datasets import CoraFull, Planetoid, CitationFull\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "from models import GAT, GraphSAGE, GIN\n",
    "from utils import train_model, test_model, train_constrative_model, valid_model\n",
    "from mean_average_distance import MAD, MADGap\n",
    "from virtualnode import VirtualClassNode_init, UnidirectionalVirtualClassNode_init, VirtualClassNode, UnidirectionalVirtualClassNode\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH = 'results'\n",
    "EARLY_STOPPING = 50\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = CitationFull(root='dataset/Cora', name='Cora', transform=NormalizeFeatures())\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19793, 8710], edge_index=[2, 126842], y=[19793], train_mask=[19793], valid_mask=[19793], test_mask=[19793])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "df = pd.DataFrame(data.x)\n",
    "df['y'] = data.y\n",
    "train, valid = train_test_split(df, stratify=df.y, test_size=0.4)\n",
    "valid, test = train_test_split(valid, stratify=valid.y, test_size=0.5)\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train.index]=True\n",
    "data.valid_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.valid_mask[valid.index]=True\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test.index]=True\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = MAD(device=device, global_flag=True)\n",
    "madgap = MADGap(device, 3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = torchmetrics.F1Score(task = \"multiclass\", average=\"micro\", num_classes=dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_result = pd.DataFrame({\n",
    "                            'trial' : [],\n",
    "                            'model' : [],\n",
    "                            'virtualnode' : [],\n",
    "                            'vnode_init' : [],\n",
    "                            'temperature' : [],\n",
    "                            'constrative coef' : [],\n",
    "                            'gaussian_noise_scale' : [],\n",
    "                            'lr' : [],\n",
    "                            'train_acc' : [],\n",
    "                            'train_loss' : [],\n",
    "                            'val_acc' : [],\n",
    "                            'val_loss' : [],\n",
    "                            'test_acc' : [],\n",
    "                            'macro f1' : [],\n",
    "                            'micro f1'\n",
    "                            'minor f1' : [],\n",
    "                            'mad' : [],\n",
    "                            'madgap' : []                            \n",
    "                            })\n",
    "\n",
    "tuning_result.to_csv(\"training_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    Vnodes = trial.suggest_categorical(\"vnode\", [\"uni\", \"bi\"])\n",
    "\n",
    "    # vnode_init = trial.suggest_categorical(\"class_mean\", [\"random\", \"zero\"])\n",
    "    \n",
    "    if Vnodes == \"uni\":\n",
    "        vc = UnidirectionalVirtualClassNode()\n",
    "        data_for_tuning = vc.forward(data)\n",
    "    else:\n",
    "        vc = VirtualClassNode()\n",
    "        data_for_tuning = vc.forward(data)\n",
    "        \n",
    "    temperature = trial.suggest_float(\"temperature\", 0.1, 10)\n",
    "    constrative_coef = trial.suggest_loguniform(\"contrastive_loss_coef\", 1e-5, 1)\n",
    "    cnode_weight = trial.suggest_loguniform(\"cnode_weight\", 1, 10)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 5e-4, 1e-2)\n",
    "    positive_sampling = trial.suggest_categorical(\"positive_sampling\", [True, False])\n",
    "\n",
    "    g_noise = trial.suggest_categorical(\"g_noise\", [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n",
    "\n",
    "    model_ = trial.suggest_categorical(\"model\", [\"sage\", \"gat\", \"gin\"])\n",
    "    if model_ == \"sage\":\n",
    "        model = GraphSAGE(in_channels=dataset.num_features, hidden_channels=256, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device, noise_level=g_noise)\n",
    "    elif model_ == \"gat\":\n",
    "        model = GAT(in_channels=dataset.num_features, hidden_channels=476, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device, heads=1, noise_level=g_noise)\n",
    "    elif model_ == \"gin\":\n",
    "        model = GIN(in_channels=dataset.num_features, hidden_channels=415, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device, noise_level=g_noise)\n",
    "    print('='*110)\n",
    "    print(f'VC : {Vnodes}, lr : {lr:.5f}, temp : {temperature:.5f}, constrative coef : {constrative_coef:.5f}')\n",
    "    print(f'noise : {g_noise:.4f}, cnode weight: {cnode_weight:.2f}, positive_sampling: {positive_sampling} ')\n",
    "    max_loss = 10000\n",
    "    early_stopping_count = 0\n",
    "    print(f'Model: {model.name} | Number of parameters: {model.get_n_params()}')\n",
    "    print('')\n",
    "    model = model.to(device)\n",
    "    data_for_tuning = data_for_tuning.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    losses = []\n",
    "    accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    for epoch in range(2000):\n",
    "        loss, acc = train_constrative_model(model, data_for_tuning, optimizer, criterion, \n",
    "                                            constrative_coef=constrative_coef, \n",
    "                                            temperature=temperature, \n",
    "                                            cnode_weight=cnode_weight,\n",
    "                                            positive_sampling=positive_sampling)\n",
    "        losses.append(loss.item())\n",
    "        accs.append(100*acc)\n",
    "        val_loss, val_acc = valid_model(model, data_for_tuning, criterion, \n",
    "                                        constrative_coef=constrative_coef, temperature=temperature, \n",
    "                                        cnode_weight=cnode_weight,\n",
    "                                        positive_sampling = positive_sampling)\n",
    "        val_accs.append(100*val_acc)\n",
    "        if val_loss < max_loss:\n",
    "            max_loss = val_loss\n",
    "            early_stopping_count = 0\n",
    "        else:\n",
    "            early_stopping_count += 1\n",
    "            if early_stopping_count > EARLY_STOPPING:\n",
    "                print(\"Early stopping..\")\n",
    "                break\n",
    "        if epoch%20==0:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train Acc: {100*acc:.2f}, Valid Loss: {val_loss:.4f}, Valid Acc: {100*val_acc:.2f}')\n",
    "        if epoch > 1000:\n",
    "            if val_acc < 0.4:\n",
    "                print('underfitting...')\n",
    "                break\n",
    "    report = test_model(model, data_for_tuning)\n",
    "    result = pd.DataFrame(report).T\n",
    "    result_sliced = result.iloc[:-3 if len(result) < 23 else 20, :]\n",
    "    test_acc = result.loc['accuracy'][0]\n",
    "    result.loc['minorities-f1',:] = result_sliced.mean(axis=0)\n",
    "    result.to_csv(os.path.join(SAVE_PATH, f'{model.name}_layers{model.num_of_hidden_layers}_neurons{model.hidden_channels}'+'.csv'))\n",
    "    result = model(data_for_tuning.x.to(device), data_for_tuning.edge_index.to(device))[0].cpu()\n",
    "    global_mad = mad(result).item()\n",
    "    mad_gap = madgap(result, data_for_tuning.edge_index).item()\n",
    "\n",
    "    model.eval()\n",
    "    out, _ = model(data_for_tuning.x, data_for_tuning.edge_index)\n",
    "    pred = out.argmax(dim=-1)\n",
    "    f1 = f1score(data_for_tuning.y[data_for_tuning.valid_mask], pred[data_for_tuning.valid_mask])\n",
    "\n",
    "    exp_result_dict = {\n",
    "        'trial' : trial.number,\n",
    "        'model' : model.name,\n",
    "        'virtualnode' : vc,\n",
    "        #'vnode_init' : vnode_init,\n",
    "        'temperature' : temperature,\n",
    "        'constrative coef' : constrative_coef,\n",
    "        'gaussian_noise_scale'  : g_noise,\n",
    "        'lr' : lr,\n",
    "        'train_acc' : acc,\n",
    "        'train_loss' : loss,\n",
    "        'val_acc' : val_acc,\n",
    "        'val_loss' : val_loss,\n",
    "        'test_acc' : test_acc,\n",
    "        'macro f1' : pd.DataFrame(report).T.loc['macro avg', 'f1-score'],\n",
    "        'micro f1' : pd.DataFrame(report).T.loc['weighted avg', 'f1-score'],\n",
    "        'minor f1' : pd.DataFrame(report).T[:-3].sort_values(by='support', ascending=False)[-11:].mean()['f1-score'],\n",
    "        'mad' : global_mad,\n",
    "        'madgap' : mad_gap                            \n",
    "    }\n",
    "    \n",
    "    \n",
    "    tuning_result = pd.read_csv(\"training_res.csv\")\n",
    "    exp_result_dict = pd.DataFrame(exp_result_dict, index=[trial.number])\n",
    "    pd.concat([tuning_result, exp_result_dict], axis=0).to_csv(\"training_res.csv\", index=False)\n",
    "    \n",
    "    torch.save(model.state_dict() , \"model_file/{}_{}.pt\".format(model.name, str(trial.number)))\n",
    "                    \n",
    "    print(f'global_mad: {global_mad}')\n",
    "    print(f'madgap: {mad_gap}')\n",
    "    print(f'Test Acc: {100*test_acc}')\n",
    "    \n",
    "    print('==========================================', end='\\n\\n')\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-06 18:46:55,930]\u001b[0m A new study created in memory with name: no-name-b81fdf8c-3802-4f5d-8e50-f0778a9a1cec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "VC : bi, lr : 0.00153, temp : 3.85288, constrative coef : 0.01068\n",
      "noise : 0.0000, cnode weight: 5.48, positive_sampling: False \n",
      "Model: GIN | Number of parameters: 4826865\n",
      "\n",
      "Epoch: 000, Train Loss: 42.1312, Train Acc: 0.09, Valid Loss: 46.6906, Valid Acc: 2.31\n",
      "Epoch: 020, Train Loss: 4.1099, Train Acc: 45.45, Valid Loss: 123.3125, Valid Acc: 0.69\n",
      "Epoch: 040, Train Loss: 2.0100, Train Acc: 66.67, Valid Loss: 84.7812, Valid Acc: 2.43\n",
      "Epoch: 060, Train Loss: 1.3225, Train Acc: 88.87, Valid Loss: 3.8145, Valid Acc: 17.47\n",
      "Epoch: 080, Train Loss: 0.8644, Train Acc: 90.94, Valid Loss: 0.5685, Valid Acc: 24.27\n",
      "Epoch: 100, Train Loss: 0.5239, Train Acc: 94.83, Valid Loss: 0.3204, Valid Acc: 27.53\n",
      "Epoch: 120, Train Loss: 0.3917, Train Acc: 95.94, Valid Loss: 0.2185, Valid Acc: 29.31\n",
      "Epoch: 140, Train Loss: 0.3040, Train Acc: 97.46, Valid Loss: 0.1490, Valid Acc: 29.64\n",
      "Epoch: 160, Train Loss: 0.2163, Train Acc: 98.09, Valid Loss: 0.1076, Valid Acc: 30.70\n",
      "Epoch: 180, Train Loss: 0.1884, Train Acc: 98.01, Valid Loss: 0.0866, Valid Acc: 31.50\n",
      "Epoch: 200, Train Loss: 0.1645, Train Acc: 98.44, Valid Loss: 0.0713, Valid Acc: 30.88\n",
      "Epoch: 220, Train Loss: 0.1302, Train Acc: 98.92, Valid Loss: 0.0572, Valid Acc: 31.67\n",
      "Epoch: 240, Train Loss: 0.1085, Train Acc: 99.15, Valid Loss: 0.0487, Valid Acc: 31.30\n",
      "Epoch: 260, Train Loss: 0.1063, Train Acc: 99.25, Valid Loss: 0.0392, Valid Acc: 31.55\n",
      "Epoch: 280, Train Loss: 0.0763, Train Acc: 99.47, Valid Loss: 0.0328, Valid Acc: 31.92\n",
      "Epoch: 300, Train Loss: 0.1121, Train Acc: 99.52, Valid Loss: 0.0276, Valid Acc: 32.51\n",
      "Epoch: 320, Train Loss: 0.0747, Train Acc: 99.37, Valid Loss: 0.0235, Valid Acc: 31.94\n",
      "Epoch: 340, Train Loss: 0.0549, Train Acc: 99.69, Valid Loss: 0.0214, Valid Acc: 31.37\n",
      "Epoch: 360, Train Loss: 0.0489, Train Acc: 99.63, Valid Loss: 0.0197, Valid Acc: 32.69\n",
      "Epoch: 380, Train Loss: 0.0404, Train Acc: 99.81, Valid Loss: 0.0163, Valid Acc: 32.54\n",
      "Epoch: 400, Train Loss: 0.0313, Train Acc: 99.84, Valid Loss: 0.0154, Valid Acc: 30.23\n",
      "Epoch: 420, Train Loss: 0.0415, Train Acc: 99.76, Valid Loss: 0.0125, Valid Acc: 32.46\n",
      "Epoch: 440, Train Loss: 0.0343, Train Acc: 99.80, Valid Loss: 0.0112, Valid Acc: 31.52\n",
      "Epoch: 460, Train Loss: 0.0249, Train Acc: 99.88, Valid Loss: 0.0101, Valid Acc: 31.03\n",
      "Epoch: 480, Train Loss: 0.0228, Train Acc: 99.87, Valid Loss: 0.0090, Valid Acc: 32.69\n",
      "Epoch: 500, Train Loss: 0.0266, Train Acc: 99.90, Valid Loss: 0.0080, Valid Acc: 31.15\n",
      "Epoch: 520, Train Loss: 0.0289, Train Acc: 99.90, Valid Loss: 0.0069, Valid Acc: 31.65\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'virtualnode' : [UnidirectionalVirtualClassNode(), VirtualClassNode()],\n",
    "    'temperature' : np.linspace(0.1, 1, num=10),\n",
    "    'constrative_coef' : np.logspace(-4, -1, 6),\n",
    "    'lr': np.logspace(-4, -2, 5)\n",
    "}\n",
    "\n",
    "tuning_result = pd.DataFrame({\n",
    "                            'model' : [],\n",
    "                            'virtualnode' : [],\n",
    "                            'temperature' : [],\n",
    "                            'constrative coef' : [],\n",
    "                            'lr' : [],\n",
    "                            'train_acc' : [],\n",
    "                            'train_loss' : [],\n",
    "                            'val_acc' : [],\n",
    "                            'val_loss' : [],\n",
    "                            'test_acc' : [],\n",
    "                            'macro f1' : [],\n",
    "                            'micro f1'\n",
    "                            'minor f1' : [],\n",
    "                            'mad' : [],\n",
    "                            'madgap' : []                            \n",
    "                            })\n",
    "tuning_result.to_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VC : UnidirectionalVirtualClassNode(), temp : 0.10000, constrative coef : 0.00010, lr : 0.00010 \n",
      "Model: GraphSAGE | Number of parameters: 4853760\n",
      "Epoch: 000, Train Loss: 4.3002, Train Acc: 1.00, Valid Loss: 4.3164, Valid Acc: 0.79\n",
      "Epoch: 010, Train Loss: 4.2717, Train Acc: 4.07, Valid Loss: 4.2959, Valid Acc: 3.92\n",
      "Epoch: 020, Train Loss: 4.2500, Train Acc: 4.24, Valid Loss: 4.2786, Valid Acc: 4.64\n",
      "Epoch: 030, Train Loss: 4.2269, Train Acc: 4.59, Valid Loss: 4.2478, Valid Acc: 4.64\n",
      "Epoch: 040, Train Loss: 4.1707, Train Acc: 4.63, Valid Loss: 4.1765, Valid Acc: 4.27\n",
      "Epoch: 050, Train Loss: 4.0989, Train Acc: 4.31, Valid Loss: 4.1030, Valid Acc: 4.27\n",
      "Epoch: 060, Train Loss: 4.0783, Train Acc: 4.52, Valid Loss: 4.0855, Valid Acc: 4.64\n",
      "Epoch: 070, Train Loss: 4.0666, Train Acc: 4.69, Valid Loss: 4.0743, Valid Acc: 4.64\n",
      "Epoch: 080, Train Loss: 4.0565, Train Acc: 4.93, Valid Loss: 4.0664, Valid Acc: 4.64\n",
      "Epoch: 090, Train Loss: 4.0510, Train Acc: 4.65, Valid Loss: 4.0586, Valid Acc: 4.64\n",
      "Epoch: 100, Train Loss: 4.0374, Train Acc: 4.68, Valid Loss: 4.0477, Valid Acc: 4.64\n",
      "Epoch: 110, Train Loss: 4.0220, Train Acc: 4.91, Valid Loss: 4.0306, Valid Acc: 4.64\n",
      "Epoch: 120, Train Loss: 3.9926, Train Acc: 4.75, Valid Loss: 3.9985, Valid Acc: 4.64\n",
      "Epoch: 130, Train Loss: 3.9281, Train Acc: 4.73, Valid Loss: 3.9311, Valid Acc: 4.82\n",
      "Epoch: 140, Train Loss: 3.8001, Train Acc: 7.20, Valid Loss: 3.7933, Valid Acc: 7.89\n",
      "Epoch: 150, Train Loss: 3.6890, Train Acc: 7.85, Valid Loss: 3.6850, Valid Acc: 9.56\n",
      "Epoch: 160, Train Loss: 3.5962, Train Acc: 10.33, Valid Loss: 3.5937, Valid Acc: 11.29\n",
      "Epoch: 170, Train Loss: 3.4945, Train Acc: 10.80, Valid Loss: 3.4924, Valid Acc: 11.74\n",
      "Epoch: 180, Train Loss: 3.3953, Train Acc: 10.96, Valid Loss: 3.4077, Valid Acc: 11.64\n",
      "Epoch: 190, Train Loss: 3.3341, Train Acc: 11.97, Valid Loss: 3.3437, Valid Acc: 12.71\n",
      "Epoch: 200, Train Loss: 3.2788, Train Acc: 12.16, Valid Loss: 3.2924, Valid Acc: 12.83\n",
      "Epoch: 210, Train Loss: 3.2250, Train Acc: 13.17, Valid Loss: 3.2466, Valid Acc: 13.68\n",
      "Epoch: 220, Train Loss: 3.1779, Train Acc: 13.63, Valid Loss: 3.2038, Valid Acc: 14.47\n",
      "Epoch: 230, Train Loss: 3.1307, Train Acc: 14.64, Valid Loss: 3.1633, Valid Acc: 15.02\n",
      "Epoch: 240, Train Loss: 3.0882, Train Acc: 15.12, Valid Loss: 3.1228, Valid Acc: 16.41\n",
      "Epoch: 250, Train Loss: 3.0497, Train Acc: 16.17, Valid Loss: 3.0802, Valid Acc: 17.85\n",
      "Epoch: 260, Train Loss: 3.0014, Train Acc: 17.73, Valid Loss: 3.0341, Valid Acc: 19.46\n",
      "Epoch: 270, Train Loss: 2.9370, Train Acc: 19.94, Valid Loss: 2.9838, Valid Acc: 21.54\n",
      "Epoch: 280, Train Loss: 2.8892, Train Acc: 20.75, Valid Loss: 2.9288, Valid Acc: 22.54\n",
      "Epoch: 290, Train Loss: 2.8256, Train Acc: 22.32, Valid Loss: 2.8703, Valid Acc: 24.30\n",
      "Epoch: 300, Train Loss: 2.7647, Train Acc: 23.93, Valid Loss: 2.8062, Valid Acc: 25.44\n",
      "Epoch: 310, Train Loss: 2.6962, Train Acc: 25.91, Valid Loss: 2.7399, Valid Acc: 27.77\n",
      "Epoch: 320, Train Loss: 2.6198, Train Acc: 28.29, Valid Loss: 2.6756, Valid Acc: 29.34\n",
      "Epoch: 330, Train Loss: 2.5652, Train Acc: 28.86, Valid Loss: 2.6196, Valid Acc: 30.63\n",
      "Epoch: 340, Train Loss: 2.5107, Train Acc: 30.61, Valid Loss: 2.5711, Valid Acc: 32.17\n",
      "Epoch: 350, Train Loss: 2.4675, Train Acc: 31.97, Valid Loss: 2.5281, Valid Acc: 33.90\n",
      "Epoch: 360, Train Loss: 2.4133, Train Acc: 33.56, Valid Loss: 2.4884, Valid Acc: 35.44\n",
      "Epoch: 370, Train Loss: 2.3834, Train Acc: 33.85, Valid Loss: 2.4504, Valid Acc: 36.41\n",
      "Epoch: 380, Train Loss: 2.3352, Train Acc: 36.32, Valid Loss: 2.4152, Valid Acc: 37.53\n",
      "Epoch: 390, Train Loss: 2.2901, Train Acc: 37.15, Valid Loss: 2.3810, Valid Acc: 39.02\n",
      "Epoch: 400, Train Loss: 2.2576, Train Acc: 38.55, Valid Loss: 2.3459, Valid Acc: 40.23\n",
      "Epoch: 410, Train Loss: 2.2176, Train Acc: 40.03, Valid Loss: 2.3097, Valid Acc: 40.83\n",
      "Epoch: 420, Train Loss: 2.1686, Train Acc: 41.03, Valid Loss: 2.2731, Valid Acc: 42.62\n",
      "Epoch: 430, Train Loss: 2.1149, Train Acc: 42.07, Valid Loss: 2.2262, Valid Acc: 43.56\n",
      "Epoch: 440, Train Loss: 2.0655, Train Acc: 44.45, Valid Loss: 2.1773, Valid Acc: 45.27\n",
      "Epoch: 450, Train Loss: 2.0100, Train Acc: 45.89, Valid Loss: 2.1280, Valid Acc: 46.41\n",
      "Epoch: 460, Train Loss: 1.9541, Train Acc: 47.41, Valid Loss: 2.0777, Valid Acc: 47.75\n",
      "Epoch: 470, Train Loss: 1.8966, Train Acc: 48.41, Valid Loss: 2.0303, Valid Acc: 49.09\n",
      "Epoch: 480, Train Loss: 1.8478, Train Acc: 50.31, Valid Loss: 1.9872, Valid Acc: 50.24\n",
      "Epoch: 490, Train Loss: 1.8019, Train Acc: 51.38, Valid Loss: 1.9487, Valid Acc: 51.35\n",
      "Epoch: 500, Train Loss: 1.7528, Train Acc: 52.72, Valid Loss: 1.9159, Valid Acc: 52.22\n",
      "Epoch: 510, Train Loss: 1.7197, Train Acc: 53.28, Valid Loss: 1.8874, Valid Acc: 53.29\n",
      "Epoch: 520, Train Loss: 1.6838, Train Acc: 54.50, Valid Loss: 1.8616, Valid Acc: 54.03\n",
      "Epoch: 530, Train Loss: 1.6539, Train Acc: 54.71, Valid Loss: 1.8392, Valid Acc: 54.98\n",
      "Epoch: 540, Train Loss: 1.6231, Train Acc: 56.39, Valid Loss: 1.8198, Valid Acc: 55.42\n",
      "Epoch: 550, Train Loss: 1.5946, Train Acc: 56.80, Valid Loss: 1.8026, Valid Acc: 55.92\n",
      "Epoch: 560, Train Loss: 1.5655, Train Acc: 58.47, Valid Loss: 1.7856, Valid Acc: 56.61\n",
      "Epoch: 570, Train Loss: 1.5320, Train Acc: 58.56, Valid Loss: 1.7722, Valid Acc: 57.01\n",
      "Epoch: 580, Train Loss: 1.5244, Train Acc: 59.05, Valid Loss: 1.7572, Valid Acc: 57.61\n",
      "Epoch: 590, Train Loss: 1.4987, Train Acc: 59.08, Valid Loss: 1.7443, Valid Acc: 58.05\n",
      "Epoch: 600, Train Loss: 1.4717, Train Acc: 59.91, Valid Loss: 1.7336, Valid Acc: 58.48\n",
      "Epoch: 610, Train Loss: 1.4602, Train Acc: 60.44, Valid Loss: 1.7233, Valid Acc: 58.80\n",
      "Epoch: 620, Train Loss: 1.4467, Train Acc: 61.40, Valid Loss: 1.7130, Valid Acc: 59.25\n",
      "Epoch: 630, Train Loss: 1.4187, Train Acc: 61.92, Valid Loss: 1.7042, Valid Acc: 59.37\n",
      "Epoch: 640, Train Loss: 1.4046, Train Acc: 61.93, Valid Loss: 1.6963, Valid Acc: 59.84\n",
      "Epoch: 650, Train Loss: 1.3875, Train Acc: 62.44, Valid Loss: 1.6888, Valid Acc: 60.29\n",
      "Epoch: 660, Train Loss: 1.3635, Train Acc: 63.24, Valid Loss: 1.6835, Valid Acc: 60.26\n",
      "Epoch: 670, Train Loss: 1.3504, Train Acc: 63.48, Valid Loss: 1.6771, Valid Acc: 60.64\n",
      "Epoch: 680, Train Loss: 1.3283, Train Acc: 63.91, Valid Loss: 1.6722, Valid Acc: 60.88\n",
      "Epoch: 690, Train Loss: 1.3277, Train Acc: 64.04, Valid Loss: 1.6662, Valid Acc: 61.01\n",
      "Epoch: 700, Train Loss: 1.3080, Train Acc: 64.20, Valid Loss: 1.6622, Valid Acc: 61.16\n",
      "Epoch: 710, Train Loss: 1.3020, Train Acc: 65.01, Valid Loss: 1.6578, Valid Acc: 61.53\n",
      "Epoch: 720, Train Loss: 1.2839, Train Acc: 65.40, Valid Loss: 1.6525, Valid Acc: 61.65\n",
      "Epoch: 730, Train Loss: 1.2720, Train Acc: 65.03, Valid Loss: 1.6508, Valid Acc: 61.53\n",
      "Epoch: 740, Train Loss: 1.2560, Train Acc: 65.68, Valid Loss: 1.6471, Valid Acc: 61.83\n",
      "Epoch: 750, Train Loss: 1.2442, Train Acc: 66.12, Valid Loss: 1.6437, Valid Acc: 62.35\n",
      "Epoch: 760, Train Loss: 1.2423, Train Acc: 65.91, Valid Loss: 1.6392, Valid Acc: 62.32\n",
      "Epoch: 770, Train Loss: 1.2302, Train Acc: 66.42, Valid Loss: 1.6387, Valid Acc: 62.22\n",
      "Epoch: 780, Train Loss: 1.2189, Train Acc: 66.82, Valid Loss: 1.6347, Valid Acc: 62.45\n",
      "Epoch: 790, Train Loss: 1.2099, Train Acc: 67.16, Valid Loss: 1.6344, Valid Acc: 62.87\n",
      "Epoch: 800, Train Loss: 1.2025, Train Acc: 67.06, Valid Loss: 1.6356, Valid Acc: 63.02\n",
      "Epoch: 810, Train Loss: 1.1911, Train Acc: 67.12, Valid Loss: 1.6327, Valid Acc: 63.37\n",
      "Epoch: 820, Train Loss: 1.1836, Train Acc: 67.33, Valid Loss: 1.6309, Valid Acc: 63.09\n",
      "Epoch: 830, Train Loss: 1.1757, Train Acc: 67.38, Valid Loss: 1.6293, Valid Acc: 63.24\n",
      "Epoch: 840, Train Loss: 1.1571, Train Acc: 67.88, Valid Loss: 1.6268, Valid Acc: 63.24\n",
      "Epoch: 850, Train Loss: 1.1618, Train Acc: 67.63, Valid Loss: 1.6233, Valid Acc: 63.37\n",
      "Epoch: 860, Train Loss: 1.1575, Train Acc: 67.86, Valid Loss: 1.6237, Valid Acc: 63.12\n",
      "Epoch: 870, Train Loss: 1.1426, Train Acc: 68.37, Valid Loss: 1.6218, Valid Acc: 63.39\n",
      "Epoch: 880, Train Loss: 1.1370, Train Acc: 69.07, Valid Loss: 1.6233, Valid Acc: 63.24\n",
      "Epoch: 890, Train Loss: 1.1259, Train Acc: 68.47, Valid Loss: 1.6225, Valid Acc: 63.37\n",
      "Epoch: 900, Train Loss: 1.1255, Train Acc: 68.79, Valid Loss: 1.6219, Valid Acc: 63.42\n",
      "Epoch: 910, Train Loss: 1.1187, Train Acc: 68.77, Valid Loss: 1.6188, Valid Acc: 63.39\n",
      "Epoch: 920, Train Loss: 1.1180, Train Acc: 69.13, Valid Loss: 1.6200, Valid Acc: 63.32\n",
      "Epoch: 930, Train Loss: 1.1026, Train Acc: 69.16, Valid Loss: 1.6186, Valid Acc: 63.64\n",
      "Epoch: 940, Train Loss: 1.1091, Train Acc: 69.21, Valid Loss: 1.6175, Valid Acc: 63.74\n",
      "Epoch: 950, Train Loss: 1.1022, Train Acc: 69.44, Valid Loss: 1.6128, Valid Acc: 63.69\n",
      "Epoch: 960, Train Loss: 1.0945, Train Acc: 69.36, Valid Loss: 1.6153, Valid Acc: 63.81\n",
      "Epoch: 970, Train Loss: 1.0765, Train Acc: 69.65, Valid Loss: 1.6148, Valid Acc: 63.89\n",
      "Epoch: 980, Train Loss: 1.0742, Train Acc: 70.15, Valid Loss: 1.6133, Valid Acc: 63.74\n",
      "Epoch: 990, Train Loss: 1.0663, Train Acc: 70.46, Valid Loss: 1.6145, Valid Acc: 63.86\n",
      "Epoch: 1000, Train Loss: 1.0732, Train Acc: 69.89, Valid Loss: 1.6115, Valid Acc: 64.01\n",
      "Epoch: 1010, Train Loss: 1.0447, Train Acc: 70.66, Valid Loss: 1.6094, Valid Acc: 64.18\n",
      "Epoch: 1020, Train Loss: 1.0481, Train Acc: 70.57, Valid Loss: 1.6148, Valid Acc: 64.41\n",
      "Epoch: 1030, Train Loss: 1.0489, Train Acc: 70.63, Valid Loss: 1.6080, Valid Acc: 64.51\n",
      "Epoch: 1040, Train Loss: 1.0368, Train Acc: 70.47, Valid Loss: 1.6098, Valid Acc: 64.83\n",
      "Epoch: 1050, Train Loss: 1.0367, Train Acc: 71.11, Valid Loss: 1.6049, Valid Acc: 64.53\n"
     ]
    }
   ],
   "source": [
    "for virtualnode in hyperparameters['virtualnode']:\n",
    "    if virtualnode is None:\n",
    "        vc = 'None'\n",
    "        data_for_tuning = data\n",
    "        constrative_flag = False\n",
    "    else:\n",
    "        vc = virtualnode\n",
    "        data_for_tuning = vc.forward(data)\n",
    "        constrative_flag = True\n",
    "        \n",
    "    for temperature in hyperparameters['temperature']:\n",
    "        for constrative_coef in hyperparameters['constrative_coef']:\n",
    "            for lr in hyperparameters['lr']:\n",
    "                models = [GraphSAGE(in_channels=dataset.num_features, hidden_channels=256, number_of_classes=dataset.num_classes, num_of_hidden_layers=4, device=device)]\n",
    "                for model in models:\n",
    "                    print(f'VC : {vc}, temp : {temperature:.5f}, constrative coef : {constrative_coef:.5f}, lr : {lr:.5f} ')\n",
    "                    max_loss = 10000\n",
    "                    early_stopping_count = 0\n",
    "                    print(f'Model: {model.name} | Number of parameters: {model.get_n_params()}')\n",
    "                    model = model.to(device)\n",
    "                    data_for_tuning = data_for_tuning.to(device)\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "                    losses = []\n",
    "                    accs = []\n",
    "                    val_losses = []\n",
    "                    val_accs = []\n",
    "                    for epoch in range(5000):\n",
    "                        loss, acc = train_constrative_model(model, data_for_tuning, optimizer, criterion, \n",
    "                                                            constrative_coef=constrative_coef, temperature=temperature)\n",
    "                        losses.append(loss.item())\n",
    "                        accs.append(100*acc)\n",
    "                        val_loss, val_acc = valid_model(model, data_for_tuning, criterion, constrative_flag=constrative_flag, \n",
    "                                                        constrative_coef=constrative_coef, temperature=temperature)\n",
    "                        val_accs.append(100*val_acc)\n",
    "                        if val_loss < max_loss:\n",
    "                            max_loss = val_loss\n",
    "                            early_stopping_count = 0\n",
    "                        else:\n",
    "                            early_stopping_count += 1\n",
    "                            if early_stopping_count > EARLY_STOPPING:\n",
    "                                print(\"Early stopping..\")\n",
    "                                break\n",
    "                        if epoch%10==0:\n",
    "                            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train Acc: {100*acc:.2f}, Valid Loss: {val_loss:.4f}, Valid Acc: {100*val_acc:.2f}')\n",
    "                        if epoch > 200:\n",
    "                            if val_acc < 0.1:\n",
    "                                print('underfitting...')\n",
    "                                break\n",
    "                    report = test_model(model, data_for_tuning)\n",
    "                    result = pd.DataFrame(report).T\n",
    "                    result_sliced = result.iloc[:-3 if len(result) < 23 else 20, :]\n",
    "                    test_acc = result.loc['accuracy'][0]\n",
    "                    result.loc['minorities-f1',:] = result_sliced.mean(axis=0)\n",
    "                    result.to_csv(os.path.join(SAVE_PATH, f'{model.name}_layers{model.num_of_hidden_layers}_neurons{model.hidden_channels}'+'.csv'))\n",
    "                    result = model(data_for_tuning.x.to(device), data_for_tuning.edge_index.to(device))[0].cpu()\n",
    "                    global_mad = mad(result).item()\n",
    "                    mad_gap = madgap(result, data_for_tuning.edge_index).item()\n",
    "                    \n",
    "                    exp_result_dict = {\n",
    "                        'model' : model.name,\n",
    "                        'virtualnode' : vc,\n",
    "                        'temperature' : temperature,\n",
    "                        'constrative coef' : constrative_coef,\n",
    "                        'lr' : lr,\n",
    "                        'train_acc' : acc,\n",
    "                        'train_loss' : loss,\n",
    "                        'val_acc' : val_acc,\n",
    "                        'val_loss' : val_loss,\n",
    "                        'test_acc' : test_acc,\n",
    "                        'macro f1' : pd.DataFrame(report).T.loc['macro avg', 'f1-score'],\n",
    "                        'micro f1' : pd.DataFrame(report).T.loc['weighted avg', 'f1-score'],\n",
    "                        'minor f1' : pd.DataFrame(report).T[:-3].sort_values(by='support', ascending=False)[-11:].mean()['f1-score'],\n",
    "                        'mad' : global_mad,\n",
    "                        'madgap' : mad_gap                            \n",
    "                    }\n",
    "                    \n",
    "                    tuning_result = tuning_result.append(exp_result_dict, ignore_index=True)\n",
    "                    \n",
    "                    print(f'global_mad: {global_mad}')\n",
    "                    print(f'madgap: {mad_gap}')\n",
    "                    print(f'Test Acc: {100*test_acc}')\n",
    "                    \n",
    "                    print('==========================================', end='\\n\\n')\n",
    "                    del model\n",
    "                    torch.cuda.empty_cache()   \n",
    "                    \n",
    "    del data_for_tuning     \n",
    "    torch.cuda.empty_cache()        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
